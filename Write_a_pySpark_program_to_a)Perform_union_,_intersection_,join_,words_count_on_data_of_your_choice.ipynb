{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L27Y1UBDk4WP",
        "outputId": "8b83e80a-2702-4a03-8e4a-f5be9e2ebb9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame 1:\n",
            "+-----+----------+\n",
            "| name|department|\n",
            "+-----+----------+\n",
            "| John|        HR|\n",
            "|Alice|   Finance|\n",
            "|  Bob|        IT|\n",
            "|Diana| Marketing|\n",
            "+-----+----------+\n",
            "\n",
            "DataFrame 2:\n",
            "+-----+---------+\n",
            "| name|  project|\n",
            "+-----+---------+\n",
            "| John|Project A|\n",
            "|Alice|Project B|\n",
            "|  Eve|Project C|\n",
            "|Frank|Project D|\n",
            "+-----+---------+\n",
            "\n",
            "DataFrame 3:\n",
            "+--------------------+\n",
            "|            sentence|\n",
            "+--------------------+\n",
            "|    Spark is amazing|\n",
            "|I love working wi...|\n",
            "|Spark makes big d...|\n",
            "+--------------------+\n",
            "\n",
            "Union of df1 and df2 (with same schema):\n",
            "+-----+---------+\n",
            "| name|     info|\n",
            "+-----+---------+\n",
            "| John|       HR|\n",
            "|Alice|  Finance|\n",
            "|  Bob|       IT|\n",
            "|Diana|Marketing|\n",
            "| John|Project A|\n",
            "|Alice|Project B|\n",
            "|  Eve|Project C|\n",
            "|Frank|Project D|\n",
            "+-----+---------+\n",
            "\n",
            "Intersection of df1 and df2:\n",
            "+----+----+\n",
            "|name|info|\n",
            "+----+----+\n",
            "+----+----+\n",
            "\n",
            "Join of df1 and df2 on 'name':\n",
            "+-----+----------+---------+\n",
            "| name|department|  project|\n",
            "+-----+----------+---------+\n",
            "|Alice|   Finance|Project B|\n",
            "| John|        HR|Project A|\n",
            "+-----+----------+---------+\n",
            "\n",
            "Word Count from sentences:\n",
            "+-------+-----+\n",
            "|   word|count|\n",
            "+-------+-----+\n",
            "|  spark|    3|\n",
            "|amazing|    1|\n",
            "|     is|    1|\n",
            "|   love|    1|\n",
            "|   with|    1|\n",
            "|  makes|    1|\n",
            "|   data|    1|\n",
            "|      i|    1|\n",
            "|   easy|    1|\n",
            "|working|    1|\n",
            "|    big|    1|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, explode, split, lower\n",
        "\n",
        "# Step 1: Start Spark session\n",
        "spark = SparkSession.builder.appName(\"Union_Intersection_Join_WordCount\").getOrCreate()\n",
        "\n",
        "# Step 2: Create sample DataFrames\n",
        "\n",
        "# DataFrame 1: Employees and Departments\n",
        "data1 = [\n",
        "    (\"John\", \"HR\"),\n",
        "    (\"Alice\", \"Finance\"),\n",
        "    (\"Bob\", \"IT\"),\n",
        "    (\"Diana\", \"Marketing\")\n",
        "]\n",
        "columns1 = [\"name\", \"department\"]\n",
        "df1 = spark.createDataFrame(data1, columns1)\n",
        "\n",
        "# DataFrame 2: Employees and Projects (some names overlap with df1)\n",
        "data2 = [\n",
        "    (\"John\", \"Project A\"),\n",
        "    (\"Alice\", \"Project B\"),\n",
        "    (\"Eve\", \"Project C\"),\n",
        "    (\"Frank\", \"Project D\")\n",
        "]\n",
        "columns2 = [\"name\", \"project\"]\n",
        "df2 = spark.createDataFrame(data2, columns2)\n",
        "\n",
        "# DataFrame 3: Sentences for word count\n",
        "data3 = [\n",
        "    (\"Spark is amazing\",),\n",
        "    (\"I love working with Spark\",),\n",
        "    (\"Spark makes big data easy\",)\n",
        "]\n",
        "columns3 = [\"sentence\"]\n",
        "df3 = spark.createDataFrame(data3, columns3)\n",
        "\n",
        "# Show initial DataFrames\n",
        "print(\"DataFrame 1:\")\n",
        "df1.show()\n",
        "print(\"DataFrame 2:\")\n",
        "df2.show()\n",
        "print(\"DataFrame 3:\")\n",
        "df3.show()\n",
        "\n",
        "# Step 3: Perform Union (requires same schema)\n",
        "# For demonstration, we'll make both have same schema\n",
        "df1_renamed = df1.withColumnRenamed(\"department\", \"info\")\n",
        "df2_renamed = df2.withColumnRenamed(\"project\", \"info\")\n",
        "\n",
        "union_df = df1_renamed.union(df2_renamed)\n",
        "print(\"Union of df1 and df2 (with same schema):\")\n",
        "union_df.show()\n",
        "\n",
        "# Step 4: Perform Intersection (common rows only)\n",
        "# Let's intersect by common schema and values\n",
        "intersection_df = df1_renamed.intersect(df2_renamed)\n",
        "print(\"Intersection of df1 and df2:\")\n",
        "intersection_df.show()\n",
        "\n",
        "# Step 5: Perform Join on \"name\"\n",
        "join_df = df1.join(df2, on=\"name\", how=\"inner\")\n",
        "print(\"Join of df1 and df2 on 'name':\")\n",
        "join_df.show()\n",
        "\n",
        "# Step 6: Word Count from sentences\n",
        "words_df = df3.select(explode(split(lower(col(\"sentence\")), \" \")).alias(\"word\"))\n",
        "word_count = words_df.groupBy(\"word\").count().orderBy(\"count\", ascending=False)\n",
        "print(\"Word Count from sentences:\")\n",
        "word_count.show()\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()\n"
      ]
    }
  ]
}